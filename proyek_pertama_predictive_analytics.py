# -*- coding: utf-8 -*-
"""Proyek Pertama : Predictive Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d_ImWIszOvf-KyJBVXt0bcnOwIsNJUy5

# **Pendidikan (Students Performance in Exams)**
**Sumber Dataset**

https://www.kaggle.com/datasets/spscientist/students-performance-in-exams



*   **Nama:** Maylina Nur'aini
*   **Email:** maylinanuraini@gmail.com
*   **ID Dicoding:** MC444D5X0679

# **Import Library**
"""

import os
import zipfile
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
from sklearn.preprocessing import  OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.metrics import mean_squared_error

"""## **Data Loading**"""

# Upload fie json
from google.colab import files
files.upload()

# Setup Api key
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

#Download dataset dari Kaggle
!kaggle datasets download -d spscientist/students-performance-in-exams

# Unzip file dataset
!unzip students-performance-in-exams.zip

# Membaca file csv
df = pd.read_csv("StudentsPerformance.csv")

# Menampilkan 5 baris pertama
df.head()

"""Pada Data loading ini, file kaggle.json yang berisi kunci API Kaggle diunggah untuk melakukan autentikasi. Kunci ini kemudian dipindahkan ke direktori khusus agar sistem dapat mengenali dan mengizinkan akses ke Kaggle melalui API. Setelah proses autentikasi berhasil, dataset bernama students-performance-in-exams diunduh menggunakan perintah API Kaggle. File dataset yang biasanya berupa arsip ZIP kemudian diekstrak untuk mendapatkan file CSV yang berisi data. Selanjutnya, file CSV tersebut dibaca menggunakan pustaka pandas ke dalam sebuah DataFrame. Untuk mendapatkan gambaran awal mengenai isi dataset, lima baris pertama dari DataFrame tersebut ditampilkan menggunakan fungsi head(). Langkah ini memudahkan dalam memahami struktur dan tipe data sebelum melanjutkan ke proses analisis lebih lanjut.

# **Data Understanding**
"""

# Menampilkan informasi umum dataset
df.info()

# Menampilkan statistik deskriptif untuk kolom numerik
df.describe()

# Menampilkan jumlah baris dan kolom dalam bentuk tuple
df.shape

# Menampilkan jumlah nilai unik di setiap kolomnya
df.nunique()

# Menampilkan missing values
df.isna().sum()

# Menampilkan data duplikat
print("Jumlah duplikasi: ", df.duplicated().sum())

# Memilih hanya kolom numerik
df_outlier = df.select_dtypes(exclude=['object'])

# Membuat boxplot untuk setiap kolom numerik
for column in df_outlier:
    plt.figure(figsize=(7, 5))
    sns.boxplot(data=df_outlier, x=column)
    plt.title(f'Boxplot untuk kolom: {column}')
    plt.show()

"""- Pada proses Data Understanding ini, meliputi pengecekan informasi umum menggunakan df.info(), statistik deskriptif dengan df.describe(), dan melihat ukuran data lewat df.shape. Jumlah nilai unik diperiksa dengan df.nunique(), sementara df.isna().sum() dan df.duplicated().sum() digunakan untuk mendeteksi missing values dan data duplikat. Untuk mengenali outlier, dibuat boxplot pada kolom numerik yang menunjukkan data ekstrem di luar rentang interkuartil. Semua langkah ini penting untuk menilai kualitas data sebelum analisis lebih lanjut.
- Dari hasil analisi menunjukkan tidak terdapat 0 duplikasi dalam datasetnya. Selain itu juga terdeteksi outlier di kolom math score, reading score, dan writing score yang perlu untuk ditangani sebelum di analisis lebih lanjut.

# **Exploratory Data Analysis (EDA)**

## **EDA - Univariate Analysis**

Pada tahap ini Univariate Analysis, dilakukan analisis distribusi fitur kategorikal ('gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course') dengan hitung jumlah dan presentase kategori, dan juga divisualisasikan dengan diagram batang. Untuk fitur numerik (math score, reading score, dan writing score) distribusi data divisualisasikan dengan histrogram.

**Fitur Kategorikal**
"""

# Menentukan fitur kategorikal
categorical_features = ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']

# Analisis distribusi data untuk fitur kategorikal
feature = categorical_features[0]
count = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_baru = pd.DataFrame({'jumlah sampel': count, 'persentase': percent.round(1)})

# Menampilkan hasil dalam bentuk tabel
print(df_baru)

# Visualisasi distribusi kategori
count.plot(kind='bar', title=feature);

"""- Distribusi fitur kategorikal ini menunjukkan female (51,8%) dan male (48,2)
- Female lebih dominan dibandingkan dengan male.

**Fitur Numerik**
"""

# Menentukan fitur numerik
numerical_features = ['math score', 'reading score', 'writing score']

# Menampilkan histogram data yang sudah dibersihkan
df.hist(bins=50, figsize=(20,15))
plt.show()

"""- math score: Distribusi cenderung normal, puncaknya di sekitar nilai tengah. Ada beberapa siswa dengan skor rendah.
- reading score: Distribusi juga cenderung normal, dengan puncak di sekitar nilai tengah. Terlihat lebih sedikit siswa dengan skor sangat rendah dibandingkan math score.
- writing score: Distribusi mirip dengan reading score, cenderung normal dengan puncak di sekitar nilai tengah.

## **EDA - Multivariate Analysis**

Pada tahap ini Multivariate Analysis, melakukan eksplorasi hubungan antar beberapa fitur dalam dataset secara bersamaan. Tujuannya adalah untuk mengidentifikasi pola atau keterkaitan antara variabel-variabel yang berbeda.

- Analisis Hubungan Fitur Kategorikal dengan Fitur Numerik (Contoh: Gender dan Math Score)
  - Menganalisis bagaimana rata-rata skor pada fitur numerik (math score) bervariasi di antara kategori-kategori dalam fitur kategorikal (gender). Visualisasi ini menggunakan diagram batang (bar plot) untuk membandingkan rata-rata skor antar kelompok.
- Analisis Interaksi Antar Fitur Numerik (Math Score, Reading Score, Writing Score)
  - Untuk memahami hubungan antar fitur numerik (math score, reading score, dan writing score), menggunakan pairplot. Pairplot menampilkan scatter plot untuk setiap kombinasi pasangan fitur numerik, serta histogram untuk distribusi setiap fitur numerik secara individual. Visualisasi ini membantu melihat pola sebaran data dan potensi hubungan antar variabel.
- Matriks Korelasi dan Visualisasi dengan Heatmap
  - Menghitung matriks korelasi antar fitur numerik (math score, reading score, dan writing score). Matriks korelasi menunjukkan kekuatan dan arah hubungan linier antar pasangan variabel. Hasil perhitungan ini akan divisualisasikan menggunakan heatmap, di mana warna sel menunjukkan besarnya koefisien korelasi. Heatmap memudahkan identifikasi fitur-fitur yang memiliki korelasi kuat, baik positif maupun negatif.

**Categorical Features**
"""

# Menentukan fitur kategorikal
categorical_features = ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course']

# Loop untuk membuat plot untuk setiap kolom kategori
for col in categorical_features:
    sns.catplot(x=col, y='math score', kind="bar", dodge=False, height=4, aspect=3, data=df, hue=col, palette="Set3", legend=False)
    plt.title("Rata-rata 'math scrore' Relatif terhadap - {}".format(col))
    plt.show()

# Loop untuk membuat plot untuk setiap kolom kategori
for col in categorical_features:
    sns.catplot(x=col, y='reading score', kind="bar", dodge=False, height=4, aspect=3, data=df, hue=col, palette="Set3", legend=False)
    plt.title("Rata-rata 'math scrore' Relatif terhadap - {}".format(col))
    plt.show()

# Loop untuk membuat plot untuk setiap kolom kategori
for col in categorical_features:
    sns.catplot(x=col, y='writing score', kind="bar", dodge=False, height=4, aspect=3, data=df, hue=col, palette="Set3", legend=False)
    plt.title("Rata-rata 'math scrore' Relatif terhadap - {}".format(col))
    plt.show()

"""**Numerical Features**"""

# Pairplot numerik
sns.pairplot(df[num_cols])
plt.suptitle("Pairplot of Numerical Features", y=1.02)
plt.show()

# Heatmap korelasi numerik
plt.figure(figsize=(6,5))
sns.heatmap(df[num_cols].corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap Between Scores')
plt.show()

"""Analisis fitur numerik melalui pairplot dan heatmap menunjukkan bahwa skor siswa di mata pelajaran matematika, membaca, dan menulis sangat berkorelasi positif. Hal ini mengindikasikan bahwa performa siswa di satu bidang studi cenderung mencerminkan performa mereka di bidang studi lainnya. Tidak ada tanda-tanda korelasi negatif yang signifikan antar fitur numerik ini.

# **Data Preparation**

Pada tahap Data Preparation ini, pertama-tama data yang duplikat dibuang agar tidak ada pengulangan informasi. Selanjutnya, outlier pada fitur numerik seperti (math score, reading score, writing score) diidentifikasi dan diatasi menggunakan metode IQR untuk menjaga kualitas data. Fitur kategorikal seperti (gender, race/ethnicity, parental level of education, lunch, test preparation course) diuubah menjadi variabel numerik dengan teknik one-hot encoding agar dapat diproses oleh model. Setelah itu, data dibagi menjadi data latih dan data uji untuk melatih dan menguji model secara terpisah. Fitur numerik yang ada kemudian distandarisasi menggunakan 'StandardScaler' agar memiliki skala yang seragam. Terakhir, statistik deskriptif pada data latih yang telah distandarisasi diperiksa guna memastikan bahwa data siap digunakan untuk analisis dan pemodelan lebih lanjut.

**Menghapus Data Duplikat**
"""



# Menghapus data duplikat
df_cleaned = df.drop_duplicates()

# Menampilkan data setelah duplikat dihapus
print("Jumlah duplikasi setelah dihapus: ", df_cleaned.duplicated().sum())

"""**Menangani Outliers**"""

# Menghitung Q1 dan Q3 untuk setiap kolom numerik
numerical_features = df.select_dtypes(include=['number']).columns
Q1 = df[numerical_features].quantile(0.25)
Q3 = df[numerical_features].quantile(0.75)

# Menghitung IQR dan menghapus outlier
IQR = Q3 - Q1
df = df[~((df[numerical_features] < (Q1 - 1.5 * IQR)) | (df[numerical_features] > (Q3 + 1.5 * IQR))).any(axis=1)]

# Menampilkan boxplot setelah penanganan outlier
for column in numerical_features:
    plt.figure(figsize=(8, 6))
    sns.boxplot(data=df, x=column)
    plt.title(f'Boxplot setelah outlier dihapus: {column}')
    plt.show()

"""**Encoding Fitur Kategorikal**"""

# Pilih fitur numerik
num_cols = ['math score', 'reading score', 'writing score']

# Pilih fitur input (selain target, misalnya target = math score)
X = df.drop(columns=['math score'])  # Semua kolom kecuali 'math score'
y = df['math score']                 # Target: 'math score'

# Tampilkan sebagian hasil X dan y
print("Fitur (X):")
print(X.head())

print("\nTarget (y):")
print(y.head())

"""**Train-Test-Split**"""

# Bagi data menjadi train dan test set (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Menampilkan jumlah data keseluruhan, data latih, dan data uji
print(f'Jumlah total sampel dalam dataset: {len(X)}')
print(f'Jumlah sampel pada data latih: {len(X_train)}')
print(f'Jumlah sampel pada data uji: {len(X_test)}')

"""**Standarisasi**"""

# Buat objek scaler
scaler = StandardScaler()

# Identifikasi kolom numerik
numerical_features = ['reading score', 'writing score']

# Fit dan transform fitur numerik pada data latih
X_train[num_cols] = scaler.fit_transform(X_train[num_cols])

# Transform juga fitur numerik pada data uji
X_test[num_cols] = scaler.transform(X_test[num_cols])

# Cek hasil
print("Fitur numerik setelah distandarisasi (X_train):")
print(X_train[num_cols].head())

# Menampilkan statistik deskriptif dari fitur numerik X_train setelah distandarisasi
X_train[numerical_features].describe().round(4)

"""# **Model Development**"""

# Inisialisasi DataFrame untuk hasil evaluasi
models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

"""**K-Nearest Neighbor**"""

# Membuat model prediksi KNN
knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""**Random Forest**"""

# Membuat model prediksi Random forest
RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""**Boosting**"""

# Membuat model boosting
boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)
boosting.fit(X_train, y_train)

models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train) # Corrected x_train to X_train

"""# **Evaluasi Model**

Pada tahap evaluasi model ini, data uji terlebih dahulu diubah skalanya menggunakan scaler yang sama seperti pada data latih agar konsisten. Kemudian, performa model KNN, Random Forest, dan Boosting dinilai dengan menghitung Mean Squared Error (MSE) pada data uji. Nilai MSE dari ketiga model tersebut dibandingkan dan hasilnya divisualisasikan dalam bentuk diagram batang untuk memudahkan analisis perbandingan performa masing-masing model.
"""

# Menggunakan scaler yang sudah dilatih untuk mentransformasi x_test
X_test[numerical_features] = scaler.transform(X_test[numerical_features])

# Menampilkan beberapa baris pertama dari data x_test setelah transformasi
X_test[numerical_features].head()

# Membuat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])

# Membuat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    # Corrected the variable name from x_train to X_train
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    # Corrected the variable name from x_test to X_test
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3
fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

# Melihat hasil prediksi
# Corrected x_test to X_test to match the variable name from train_test_split
prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}

# Melakukan prediksi dengan masing-masing model dan menyimpan hasilnya
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)
pd.DataFrame(pred_dict)

"""# **Interpretasi Hasil dan Keterkaitan dengan Tujuan Bisnis**

## **Problem Statement 1**

Bagaimana data akademik dan latar belakang siswa dapat dimanfaatkan untuk mengembangkan sistem prediktif skor matematika sebagai dasar pengambilan keputusan strategis di lingkungan pendidikan?

**Goal 1**

Merancang sebuah model prediksi yang mampu mengestimasi nilai matematika siswa secara akurat, sehingga sekolah dapat memperoleh gambaran potensi siswa sejak awal dan melakukan tindak lanjut yang sesuai.

**Hasil & Analisis**

Tiga algoritma machine learning dievaluasi untuk membangun model prediksi, dengan hasil sebagai berikut:
- Random Forest memberikan performa terbaik dengan tingkat kesalahan prediksi paling rendah (MSE terendah).
- Boosting menunjukkan akurasi cukup baik, meskipun masih kalah dari Random Forest.
- KNN memiliki error paling tinggi, mengindikasikan performa yang kurang optimal.

Prediksi skor matematika dari masing-masing model terhadap nilai aktual 66:
- Random Forest: 69.6
- Boosting: 74.9
- KNN: 70.7

Jadi, Random Forest lebih mampu mengenali pola kompleks antar fitur, baik numerik maupun kategorikal, menjadikannya model paling andal dalam konteks prediksi skor matematika.

**Keterkaitan dengan Tujuan Pendidikan**

Implementasi model ini membuka peluang bagi sekolah untuk:
- Mengidentifikasi siswa yang membutuhkan perhatian khusus lebih awal, bahkan sebelum nilai resmi tersedia.
- Memberikan dukungan akademik yang lebih terarah, seperti program bimbingan belajar untuk siswa tertentu.
- Menerapkan pendekatan berbasis data dalam evaluasi siswa, meningkatkan efektivitas strategi pengajaran dan manajemen kelas.

## **Problem Statement 2**

Bagaimana memilih model prediksi terbaik untuk memperkirakan nilai matematika siswa berdasarkan perbandingan performa beberapa algoritma?

**Goal 2**

Menganalisis dan membandingkan kinerja dari model KNN, Boosting, dan Random Forest untuk menentukan model dengan akurasi tertinggi yang paling sesuai diterapkan di bidang pendidikan.

**Hasil & Analisis**

Penilaian dilakukan menggunakan metrik Mean Squared Error (MSE) sebagai indikator utama akurasi prediksi. Hasil menunjukkan:
- Random Forest paling akurat, dengan prediksi paling dekat terhadap nilai sebenarnya.
- Boosting sedikit overestimate namun masih dalam batas wajar.
- KNN gagal memodelkan data secara efektif, menghasilkan error tertinggi.

Secara keseluruhan, Random Forest memberikan hasil yang konsisten dan stabil dalam berbagai pengujian.

**Manfaat Strategis untuk Sekolah**

Dengan memilih Random Forest sebagai model utama, sekolah dapat:

- Mengantisipasi pencapaian akademik siswa dengan mengandalkan data awal tanpa menunggu hasil ujian.
- Mengelola sumber daya lebih efisien, karena bantuan akademik dapat difokuskan kepada siswa yang benar-benar membutuhkan.
- Menjadikan analitik prediktif sebagai fondasi kebijakan pendidikan yang proaktif dan responsif.
"""